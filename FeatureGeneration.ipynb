{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from datetime import datetime, date\n",
    "loc_train = \"D:\\\\Stat Team Project\\\\trainHistory.csv\"\n",
    "loc_test = \"D:\\\\Stat Team Project\\\\testHistory.csv\"\n",
    "loc_offers = \"D:\\\\Stat Team Project\\\\offers.csv\"\n",
    "loc_transactions = \"D:\\\\Stat Team Project\\\\reducedDS2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def diff_days(s1,s2):\n",
    "    date_format = \"%m/%d/%Y\"\n",
    "    date_format2 = \"%Y-%m-%d\"\n",
    "    a = datetime.strptime(s1, date_format)\n",
    "    b = datetime.strptime(s2, date_format2)\n",
    "    delta = b - a\n",
    "    return delta.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#keep a dictionary with the offerdata\n",
    "offers = {}\n",
    "for e, line in enumerate( open(loc_offers) ):\n",
    "    row = line.strip().split(\",\")\n",
    "    offers[ row[0] ] = row\n",
    "\n",
    "#keep two dictionaries with the shopper id's from test and train\n",
    "train_ids = {}\n",
    "test_ids = {}\n",
    "for e, line in enumerate( open(loc_train) ):\n",
    "    if e > 0:\n",
    "        row = line.strip().split(\",\")\n",
    "        train_ids[row[0]] = row\n",
    "for e, line in enumerate( open(loc_test) ):\n",
    "    if e > 0:\n",
    "        row = line.strip().split(\",\")\n",
    "        test_ids[row[0]] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#iterate through reduced dataset \n",
    "last_id = 0\n",
    "features = defaultdict(float)\n",
    "testdf = pd.DataFrame()\n",
    "traindf = pd.DataFrame()\n",
    "for e, line in enumerate( open(loc_transactions) ):\n",
    "    if e > 0: #skip header\n",
    "        #poor man's csv reader\n",
    "        row = line.strip().split(\",\")\n",
    "        #write away the features when we get to a new shopper id\n",
    "        if last_id != row[0] and e != 1:\n",
    "\n",
    "            #generate negative features\n",
    "            if \"has_bought_company\" not in features:\n",
    "                features['never_bought_company'] = 1\n",
    "\n",
    "            if \"has_bought_category\" not in features:\n",
    "                features['never_bought_category'] = 1\n",
    "\n",
    "            if \"has_bought_brand\" not in features:\n",
    "                features['never_bought_brand'] = 1\n",
    "\n",
    "            if \"has_bought_brand\" in features and \"has_bought_category\" in features and \"has_bought_company\" in features:\n",
    "                features['has_bought_brand_company_category'] = 1\n",
    "\n",
    "            if \"has_bought_brand\" in features and \"has_bought_category\" in features:\n",
    "                features['has_bought_brand_category'] = 1\n",
    "\n",
    "            if \"has_bought_brand\" in features and \"has_bought_company\" in features:\n",
    "                features['has_bought_brand_company'] = 1\n",
    "\n",
    "            if features['label'] == 0.5:\n",
    "                testdf = testdf.append(features, ignore_index=True)\n",
    "            else:\n",
    "                traindf = traindf.append(features, ignore_index=True)\n",
    "\n",
    "            features = defaultdict(float)\n",
    "        #generate features from transaction record\n",
    "        #check if we have a test sample or train sample\n",
    "        if row[0] in train_ids or row[0] in test_ids:\n",
    "\n",
    "            #generate label and history\n",
    "            if row[0] in train_ids:\n",
    "                history = train_ids[row[0]]\n",
    "                #print(history)\n",
    "                if train_ids[row[0]][5] == \"t\":\n",
    "                    features['label'] = 1\n",
    "                else:\n",
    "                    features['label'] = 0\n",
    "            else:\n",
    "                history = test_ids[row[0]]\n",
    "                features['label'] = 0.5\n",
    "\n",
    "            features['ID'] = row[0]\n",
    "            features['offer_value'] = offers[ history[2] ][4]\n",
    "            features['offer_quantity'] = offers[ history[2] ][2]\n",
    "            offervalue = offers[ history[2] ][4]\n",
    "            features['total_spend'] += float( row[10] )\n",
    "    \n",
    "            if offers[ history[2] ][3] == row[4]:\n",
    "                features['has_bought_company'] += 1.0\n",
    "                features['has_bought_company_q'] += float( row[9] )\n",
    "                features['has_bought_company_a'] += float( row[10] )\n",
    "\n",
    "                date_diff_days = diff_days(row[6],history[-1])\n",
    "                if date_diff_days < 30:\n",
    "                    features['has_bought_company_30'] += 1.0\n",
    "                    features['has_bought_company_q_30'] += float( row[9] )\n",
    "                    features['has_bought_company_a_30'] += float( row[10] )\n",
    "                if date_diff_days < 60:\n",
    "                    features['has_bought_company_60'] += 1.0\n",
    "                    features['has_bought_company_q_60'] += float( row[9] )\n",
    "                    features['has_bought_company_a_60'] += float( row[10] )\n",
    "                if date_diff_days < 90:\n",
    "                    features['has_bought_company_90'] += 1.0\n",
    "                    features['has_bought_company_q_90'] += float( row[9] )\n",
    "                    features['has_bought_company_a_90'] += float( row[10] )\n",
    "                if date_diff_days < 180:\n",
    "                    features['has_bought_company_180'] += 1.0\n",
    "                    features['has_bought_company_q_180'] += float( row[9] )\n",
    "                    features['has_bought_company_a_180'] += float( row[10] )\n",
    "            if offers[ history[2] ][1] == row[3]:\n",
    "                features['has_bought_category'] += 1.0\n",
    "                features['has_bought_category_q'] += float( row[9] )\n",
    "                features['has_bought_category_a'] += float( row[10] )\n",
    "                date_diff_days = diff_days(row[6],history[-1])\n",
    "                if date_diff_days < 30:\n",
    "                    features['has_bought_category_30'] += 1.0\n",
    "                    features['has_bought_category_q_30'] += float( row[9] )\n",
    "                    features['has_bought_category_a_30'] += float( row[10] )\n",
    "                if date_diff_days < 60:\n",
    "                    features['has_bought_category_60'] += 1.0\n",
    "                    features['has_bought_category_q_60'] += float( row[9] )\n",
    "                    features['has_bought_category_a_60'] += float( row[10] )\n",
    "                if date_diff_days < 90:\n",
    "                    features['has_bought_category_90'] += 1.0\n",
    "                    features['has_bought_category_q_90'] += float( row[9] )\n",
    "                    features['has_bought_category_a_90'] += float( row[10] )\t\t\t\t\t\t\n",
    "                if date_diff_days < 180:\n",
    "                    features['has_bought_category_180'] += 1.0\n",
    "                    features['has_bought_category_q_180'] += float( row[9] )\n",
    "                    features['has_bought_category_a_180'] += float( row[10] )\t\t\t\t\n",
    "            if offers[ history[2] ][5] == row[5]:\n",
    "                features['has_bought_brand'] += 1.0\n",
    "                features['has_bought_brand_q'] += float( row[9] )\n",
    "                features['has_bought_brand_a'] += float( row[10] )\n",
    "                date_diff_days = diff_days(row[6],history[-1])\n",
    "                if date_diff_days < 30:\n",
    "                    features['has_bought_brand_30'] += 1.0\n",
    "                    features['has_bought_brand_q_30'] += float( row[9] )\n",
    "                    features['has_bought_brand_a_30'] += float( row[10] )\n",
    "                if date_diff_days < 60:\n",
    "                    features['has_bought_brand_60'] += 1.0\n",
    "                    features['has_bought_brand_q_60'] += float( row[9] )\n",
    "                    features['has_bought_brand_a_60'] += float( row[10] )\n",
    "                if date_diff_days < 90:\n",
    "                    features['has_bought_brand_90'] += 1.0\n",
    "                    features['has_bought_brand_q_90'] += float( row[9] )\n",
    "                    features['has_bought_brand_a_90'] += float( row[10] )\t\t\t\t\t\t\n",
    "                if date_diff_days < 180:\n",
    "                    features['has_bought_brand_180'] += 1.0\n",
    "                    features['has_bought_brand_q_180'] += float( row[9] )\n",
    "                    features['has_bought_brand_a_180'] += float( row[10] )\t\n",
    "        last_id = row[0]\n",
    "        if e % 100000 == 0:\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testdf.to_csv(\"D:\\\\Stat Team Project\\\\testdf.csv\")\n",
    "traindf.to_csv(\"D:\\\\Stat Team Project\\\\traindf.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
